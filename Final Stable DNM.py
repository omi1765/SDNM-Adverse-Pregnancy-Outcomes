{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a476f85-d58a-40b5-a6a7-777909f46027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "\n",
    "class StableDNM:\n",
    "    \"\"\"\n",
    "    Stable Dendritic Neural Model with:\n",
    "    - Log-product dendritic integration\n",
    "    - Linear soma pathway\n",
    "    - Adam optimization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        n_branches=4,\n",
    "        lr=0.01,\n",
    "        epochs=600,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        eps=1e-8\n",
    "    ):\n",
    "        self.input_dim = input_dim\n",
    "        self.n_branches = n_branches\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "\n",
    "        # Parameters\n",
    "        self.Wd = np.random.randn(n_branches, input_dim) * 0.1\n",
    "        self.Wl = np.random.randn(input_dim) * 0.1\n",
    "        self.b = 0.0\n",
    "\n",
    "        # Adam states\n",
    "        self.mWd = np.zeros_like(self.Wd)\n",
    "        self.vWd = np.zeros_like(self.Wd)\n",
    "        self.mWl = np.zeros_like(self.Wl)\n",
    "        self.vWl = np.zeros_like(self.Wl)\n",
    "        self.mb = 0.0\n",
    "        self.vb = 0.0\n",
    "        self.t = 0\n",
    "\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        z = np.clip(z, -50, 50)\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "  \n",
    "    def _forward(self, X):\n",
    "        eps = 1e-6\n",
    "\n",
    "        mult = np.abs(X[:, None, :] * self.Wd[None, :, :]) + eps\n",
    "        log_prod = np.sum(np.log(mult), axis=2)\n",
    "        dendritic = np.exp(log_prod)\n",
    "\n",
    "        soma = dendritic.sum(axis=1) + X @ self.Wl + self.b\n",
    "        y_hat = self._sigmoid(soma)\n",
    "\n",
    "        return y_hat, dendritic\n",
    "\n",
    "   \n",
    "    def _adam_update(self, param, grad, m, v):\n",
    "        m = self.beta1 * m + (1 - self.beta1) * grad\n",
    "        v = self.beta2 * v + (1 - self.beta2) * (grad ** 2)\n",
    "\n",
    "        m_hat = m / (1 - self.beta1 ** self.t)\n",
    "        v_hat = v / (1 - self.beta2 ** self.t)\n",
    "\n",
    "        param -= self.lr * m_hat / (np.sqrt(v_hat) + self.eps)\n",
    "        return param, m, v\n",
    "\n",
    " \n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.t += 1\n",
    "\n",
    "            y_pred, dendritic = self._forward(X)\n",
    "            error = y_pred - y\n",
    "            delta = error * y_pred * (1 - y_pred)\n",
    "\n",
    "            # Gradients\n",
    "            gWl = (X.T @ delta) / n\n",
    "            gb = delta.mean()\n",
    "\n",
    "            gWd = np.zeros_like(self.Wd)\n",
    "            for b in range(self.n_branches):\n",
    "                grad = (\n",
    "                    delta[:, None] * dendritic[:, b:b+1]\n",
    "                ) / (X * self.Wd[b] + 1e-6)\n",
    "                gWd[b] = grad.mean(axis=0)\n",
    "\n",
    "            # Adam updates\n",
    "            self.Wl, self.mWl, self.vWl = self._adam_update(\n",
    "                self.Wl, gWl, self.mWl, self.vWl\n",
    "            )\n",
    "            self.b, self.mb, self.vb = self._adam_update(\n",
    "                self.b, gb, self.mb, self.vb\n",
    "            )\n",
    "            self.Wd, self.mWd, self.vWd = self._adam_update(\n",
    "                self.Wd, gWd, self.mWd, self.vWd\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "   \n",
    "    def predict_proba(self, X):\n",
    "        y_hat, _ = self._forward(X)\n",
    "        return np.column_stack([1 - y_hat, y_hat])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ----------------------------\n",
    "    # LOAD DATA\n",
    "    # ----------------------------\n",
    "    df = pd.read_csv(\"Mdata_CTGAN.csv\")\n",
    "    target = \"composite_apo\"\n",
    "\n",
    "    df = df.drop(columns=[c for c in [\"Admission number \", \"Date of admission\"] if c in df.columns])\n",
    "\n",
    "    y = df[target].values\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.median()).values\n",
    "\n",
    "    print(\"Balanced class distribution:\")\n",
    "    print(pd.Series(y).value_counts())\n",
    "\n",
    "  \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        model = StableDNM(\n",
    "            input_dim=X.shape[1],\n",
    "            n_branches=4,\n",
    "            lr=0.01,\n",
    "            epochs=600\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        results.append({\n",
    "            \"Fold\": fold,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "            \"Recall\": recall_score(y_test, y_pred),\n",
    "            \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "            \"F1\": f1_score(y_test, y_pred),\n",
    "            \"Kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "            \"MCC\": matthews_corrcoef(y_test, y_pred),\n",
    "            \"AUC\": roc_auc_score(y_test, y_prob)\n",
    "        })\n",
    "\n",
    "        print(f\"StableDNM | Fold {fold} | AUC={results[-1]['AUC']:.3f}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"StableDNM_CTGAN_10fold_results.csv\", index=False)\n",
    "\n",
    "    print(\"\\nSaved: StableDNM_CTGAN_10fold_results.csv\")\n",
    "    print(\"\\nMean Performance:\")\n",
    "    print(results_df.mean(numeric_only=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
